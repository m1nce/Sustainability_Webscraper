{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wefel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "c:\\Users\\wefel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import concurrent.futures\n",
    "from happytransformer import HappyTextClassification\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import textwrap\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "CUSTOM_CONFIG_ID = os.getenv(\"CUSTOM_CONFIG_ID\")\n",
    "\n",
    "def bing_search(query, api_key, custom_config_id, num_results=10, excluded_site=''):\n",
    "    search_query = f\"{query} -site:{excluded_site}\" if excluded_site else query\n",
    "    search_url = f\"https://api.bing.microsoft.com/v7.0/custom/search?q={search_query}&customconfig={custom_config_id}\"\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    params = {'count': num_results}\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve search results: {response.status_code}, {response.text}\")\n",
    "        return []\n",
    "    results = response.json().get('webPages', {}).get('value', [])\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return []\n",
    "    urls = [result['url'] for result in results]\n",
    "    print(f\"Found URLs: {urls}\")\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/12/2024 16:06:05 - INFO - happytransformer.happy_transformer -   Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "happy_class = HappyTextClassification(model_type=\"BERT\", model_name=\"Vinoth24/environmental_claims\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_classify_content(content):\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    sentences = sent_tokenize(content)\n",
    "    classified_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if sentence:\n",
    "            wrapped_text = textwrap.fill(sentence, width=80)\n",
    "            for line in wrapped_text.split('\\n'):\n",
    "                result = happy_class.classify_text(line)\n",
    "                if result.label == \"LABEL_1\" and result.score > 0.5:\n",
    "                    clean_line = ' '.join(line.split())\n",
    "                    classified_sentences.append(clean_line)\n",
    "    return '\\n'.join(classified_sentences)\n",
    "\n",
    "def search_and_scrape(query, company_website, max_threads=10):\n",
    "    urls = bing_search(query, API_KEY, CUSTOM_CONFIG_ID, excluded_site=company_website)\n",
    "    urls_to_scrape = [url for url in urls if not any(substring in url for substring in ['.xlsx', 'sitemap', '/download', 'List', 'list'])]\n",
    "\n",
    "    with open('scraped_data.txt', 'w', encoding='utf-8') as file:\n",
    "        with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            future_to_url = {executor.submit(fetch_content, url): url for url in urls_to_scrape}\n",
    "            for future in as_completed(future_to_url):\n",
    "                url = future_to_url[future]\n",
    "                try:\n",
    "                    content = future.result()\n",
    "                    if content:\n",
    "                        processed_content = process_and_classify_content(content)\n",
    "                        if processed_content:\n",
    "                            wrapped_content = textwrap.fill(processed_content, width=120)\n",
    "                            file.write(f\"URL: {url}\\nContent:\\n{wrapped_content}\\n\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {url}: {e}\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "def fetch_content(url):\n",
    "    try:\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                return soup.get_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching: intext:\"Mia Peru\" company sustainability\n",
      "Found URLs: ['https://www.facebook.com/MIAPERU/', 'https://www.commonobjective.co/mia-peru', 'https://connectamericas.com/company/mia-peru', 'https://intengine.com/directory/profile/90341-mia-peru', 'https://www.zoominfo.com/c/mia-peru-corp/452766959', 'https://www.solunacollective.com/pages/mia', 'https://connectamericas.com/es/company/mia-peru', 'https://www.dnb.com/business-directory/company-profiles.mia_peru_corp_sac.874975a5708368c5ee61eddcad36c2b2.html', 'https://www.instagram.com/mia_peru/p/CoP3ihiM2GH/', 'http://mia-peru.com/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/12/2024 16:06:06 - INFO - happytransformer.happy_transformer -   Moving model to cpu\n",
      "05/12/2024 16:06:06 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n"
     ]
    }
   ],
   "source": [
    "company_name = \"Mia Peru\"\n",
    "company_website = \"miaperu.com\"\n",
    "print(f\"Searching: intext:\\\"{company_name}\\\" company sustainability\")\n",
    "search_and_scrape(f\"intext:\\\"{company_name}\\\" company sustainability\", company_website)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
